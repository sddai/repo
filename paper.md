Pruning
Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding. ICLR, 2016.
CNNpack: Packing Convolutional Neural Networks in the Frequency Domain. NIPS, 2016.
Pruning convolutional neural networks for resource efficient transfer learning. ICLR, 2017.
ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression. ICCV, 2017.
Packing Convolutional Neural Networks in the Frequency Domain. TPAMI, 2018.
Frequency-Domain Dynamic Pruning for Convolutional Neural Networks. NIPS2018.

Teacher-Student Paradigm
Distilling the Knowledge in a Neural Network. NIPS workshop, 2014.
FitNets: Hints for Thin Deep Nets. ICLR, 2015.
Like What You Like: Knowledge Distill via Neuron Selectivity Transfer. 2017.
Paying More Attention to Attention: Improving the Performance Of Convolutional Neural Networks via Attention Transfer. ICLR, 2017.
Learning from Multiple Teacher Networks. ACM SIGKDD, 2018.
Adversarial Learning of Portable Student Networks. AAAI, 2018.
Quantization Mimic: Towards Very Tiny CNN for Object Detection. ECCV, 2018.

Decomposition of NN Layers
MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Application. Google, 2017.
ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices. CVPR, 2018.
Shift: A Zero FLOP, Zero Parameter Alternative to Spatial Convolutions. CVPR, 2018.
MobileNetV2: Inverted Residuals and Linear Bottlenecks. CVPR, 2018.
ShuffleNetV2: Practical Guidelines for Efficient CNN Architecture Design. ECCV, 2018.
Learning Versatile Filters for Efficient Convolutional Neural Networks. NIPS, 2018.


NAS (Neural Architecture Search)
Neural Architecture Search With Reinforcement Learning. ICLR, 2017.
Large-Scale Evolution of Image Classifiers. ICML, 2017.
Genetic CNN. ICCV, 2017.
Regularized Evolution for Image Classifier Architecture Search. Google, 2018.
Towards Evolutionary Compression. ACM SIGKDD, 2018.
AMC: Automated Model Compression and Acceleration with Reinforcement Learning. ECCV, 2018.
Neural Architecture Optimization. NIPS, 2018.
Towards Evolutionary Compression. ACM SIGKDD, 2018.

rethinking imagenet pre-training  Kaiming He


行人再识别
有监督：
表征学习 [Zheng Z et al, ACM TMCCA, 2017.] 
度量学习 [M. Koestinger et al, CVPR, 2012]
迁移学习：
共享嵌入空间 [Peng et al., CVPR, 2016]
借助额外信息 [Wang et al., CVPR, 2018]
用GAN去风格迁移 [Wei et al., CVPR, 2018]



PUL(ACM TMCCA，2016)





